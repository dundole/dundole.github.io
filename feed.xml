<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-01-25T19:56:15+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">하나유월’s 데이터베이스</title><subtitle>하나유월&apos;s blog</subtitle><author><name>하나유월</name></author><entry><title type="html">[ML/사이킷런] Cross Validation (교차검증)</title><link href="http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/Cross-Validation/" rel="alternate" type="text/html" title="[ML/사이킷런] Cross Validation (교차검증)" /><published>2022-01-07T00:00:00+09:00</published><updated>2022-01-07T00:00:00+09:00</updated><id>http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/Cross-Validation</id><content type="html" xml:base="http://localhost:4000/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/Cross-Validation/"><![CDATA[<blockquote>
  <h4 id="cross-validation이란">Cross Validation이란?</h4>
  <p>교차검증, 머신러닝 모델을 평가할 땐 단순히 train set으로 모델을 학습하고, test set으로 검증을 하지만, 이런 방식을 이용하게 되면 모델이 test set에 과적합하는 문제가 발생할 수 있다. test set과 다른 데이터에 대해서는 제대로 된 결과를 도출해내지 못 할수 있다는 의미. <br />
이를 해결하고자 하는 것이 <strong>Cross Validation</strong>, 즉 교차 검증이다. 기존 train set과 test set으로만 분리되어있던 데이터를 train set에서 validation set를 분리해낸 다음, validation set을 사용해 검증하는 방식임.</p>
</blockquote>

<h5 id="1-k-fold-cross-validation-k-겹-교차검증">1. K-Fold Cross Validation (K-겹 교차검증)</h5>
<ul>
  <li>K-Fold는 일반적으로 가장 많이 사용되는 교차검증 방법임.</li>
  <li>회귀 모델에 많이 사용되며, 데이터가 독립적이고 동일한 분포를 가진 경우 사용됨.</li>
  <li>K-Fold 교차검증 과정은 다음과 같음.
    <blockquote>
      <ol>
        <li>전체 데이터셋을 Train set과 Test set으로 나눔.</li>
        <li>Train set을 K개의 폴드로 나눔.</li>
        <li>첫 번째 폴드를 Validation set으로 사용하고 나머지 폴드들을 Train set으로 사용함.</li>
        <li>즉 n번째 성능평가에선 n번째 폴드가 Validation set으로, 나머지 폴드들이 Train set으로 사용됨.</li>
        <li>총 K개의 성능평가 결과가 나오며, 이 K개의 평균이 해당 학습 모델의 성능이다.</li>
      </ol>
    </blockquote>
  </li>
</ul>
<p align="center">
<img src="/assets/images/CrossValidation_k-fold.png" width="500px" height="500px" />
</p>
<ul>
  <li>K-Fold는 데이터를 랜덤하게 잘라 사용하기 때문에, 특정한 답이 Train set에 포함되지 않을 경우 답을 제대로 도출해낼수 없는 문제점이 존재한다.</li>
</ul>

<h5 id="2-stratified-k-fold-cross-validation-계층별-k-겹-교차검증">2. Stratified K-Fold Cross Validation (계층별 K-겹 교차검증)</h5>
<ul>
  <li>뷸균형한(imbalanced) 분포도를 가진 레이블 데이터를 위한 K-Fold 방식.
    <ul>
      <li>불균형한 분포도란 특정 레이블 값이 특이하게 많거나, 적어서 값의 분포가 치우치는 것을 의미함.</li>
    </ul>
  </li>
  <li>Train set과 Validation set가 가지는 레이블 분포도가 유사하도록 검증 데이터를 추출한다.</li>
</ul>]]></content><author><name>하나유월</name></author><category term="머신러닝" /><category term="ML" /><summary type="html"><![CDATA[Cross Validation이란? 교차검증, 머신러닝 모델을 평가할 땐 단순히 train set으로 모델을 학습하고, test set으로 검증을 하지만, 이런 방식을 이용하게 되면 모델이 test set에 과적합하는 문제가 발생할 수 있다. test set과 다른 데이터에 대해서는 제대로 된 결과를 도출해내지 못 할수 있다는 의미. 이를 해결하고자 하는 것이 Cross Validation, 즉 교차 검증이다. 기존 train set과 test set으로만 분리되어있던 데이터를 train set에서 validation set를 분리해낸 다음, validation set을 사용해 검증하는 방식임.]]></summary></entry><entry><title type="html">test</title><link href="http://localhost:4000/%EB%B3%B4%EC%95%88/test/" rel="alternate" type="text/html" title="test" /><published>2022-01-06T00:00:00+09:00</published><updated>2022-01-06T00:00:00+09:00</updated><id>http://localhost:4000/%EB%B3%B4%EC%95%88/test</id><content type="html" xml:base="http://localhost:4000/%EB%B3%B4%EC%95%88/test/"><![CDATA[<blockquote>
  <h2 id="neural-news-recommendation-with-multi-head-self-attention">Neural News Recommendation with Multi-Head Self-Attention</h2>
  <p>EMNLP-IJCNLP 2019 | Nov 2019 <br />
<strong>Wu. Chuhan, Wu. Fangzhao, Ge. Suyu, Qi. Tao, Huang. Yongfeng, Xie. Xing</strong> <br />
Tsinghua University, Microsoft Research Asia <br />
DOI : <a href="https://doi.org/10.18653/v1/D19-1671">10.18653/v1/D19-1671</a></p>
</blockquote>

<blockquote>
  <h3 id="abstract">Abstract.</h3>
  <p>이 논문에서는 NRMS(multi-head self-attention)를 사용한 신경망 뉴스 추천 접근 방식을 제안한다. 저자들이 뉴스 추천에서 중요한 관측으로 여기는 몇 가지 중요한 점이 있는데, 첫번째는 뉴스 제목에서 단어간의 상호작용이 뉴스를 이해하는데 중요하단 것이고, 두번째는 뉴스 제목을 표현하는데 있어서 뉴스 제목의 단어가 서로 다른 중요도를 가질 수 있다는 점. 그리고 같은 사용자가 검색한 서로 다른 뉴스도 사용자를 표현하는데 있어 서로 다른 중요도를 가질 수 있다는 점이다. 저자들은 이러한 관측을 Multi-Head Self-Attention을 통해 뉴스 추천을 기존의 방법들보다 더 효과적으로 할 수 있음을 보여준다.</p>
</blockquote>

<p>해당 논문에서 제시한 모델의 그림은 다음과 같다.</p>
<p align="center">
<img src="/assets/images/NRMS_model.png" width="500px" height="500px" />
</p>
<p>모델은 크게 유저 인코더와 뉴스 인코더로 나뉘는데, 유저 인코더의 입력으로 뉴스 인코더의 출력이 들어가기 때문에, 뉴스 인코더부터 살펴보도록 하겠다.</p>

<p align="center">
<img src="/assets/images/NRMS_news_encoder.png" width="200px" height="300px" />
</p>
<p>뉴스 인코더는 총 3개의 레이어로 구성된다.</p>

<p>첫번째 레이어는 워드 임베딩 레이어로, 뉴스 제목의 단어들을 sequence of word에서 저차원의 임베딩 벡터 시퀀스로 변환해주는 역할을 한다.</p>

\[\begin{equation}
[w_1, w_2, ..., w_M] \rightarrow [e_1, e_2, ..., e_M]
\end{equation}\]

<p>두번째 레이어는 word-level의 multi-head self-attention 네트워크이다. 단어간의 상호작용이 뉴스 표현을 학습하는데 중요하기때문에, 저자들은 단어의 문맥적인 표현을 학습하기 위해서 multi-head self-attention을 사용할 것을 제안했다.</p>

<p>$k$번째 attention head에 의해 학습된 $i$번째 단어의 표현은 다음과 같이 계산된다.</p>

\[\begin{equation}
\alpha_{i,j}^k = {exp(e_i^TQ_k^we_j)\over \Sigma_{m=1}^M exp(e_i^TQ_k^we_m)}
\end{equation}\]

\[\begin{equation}
h_{i,k}^w = V_k^w(\Sigma_{j=1}^M\alpha_{i,j}^ke_j)
\end{equation}\]

<p>식 2의 $Q_k^w$와 식 3의 $V_k^w$는 $k$번째 self-attention head의 projection parameter들이고,$\alpha_{i,j}^k$는 $i$번째 단어와 $j$번째 단어의 상호작용의 상대적인 중요도를 나타낸다.</p>

<p>multi-head의 표현 $h_i^w$는 $h$개의 개별 self-attention head에서 생성된 $i$번째 단어의 표현들의 concatenation이다.</p>]]></content><author><name>하나유월</name></author><category term="보안" /><category term="test" /><summary type="html"><![CDATA[Neural News Recommendation with Multi-Head Self-Attention EMNLP-IJCNLP 2019 | Nov 2019 Wu. Chuhan, Wu. Fangzhao, Ge. Suyu, Qi. Tao, Huang. Yongfeng, Xie. Xing Tsinghua University, Microsoft Research Asia DOI : 10.18653/v1/D19-1671]]></summary></entry></feed>